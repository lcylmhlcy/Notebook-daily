# 我的日常科研笔记

## 模版
1. **题目**：[]()  
  **作者及接受期刊/会议**：  
  **摘要**：

---

## 笔记
1. **题目**：[Hybrid Spatio-Temporal Graph Convolutional Network: Improving Traffic Prediction with Navigation Data](https://arxiv.org/abs/2006.12715)  
  **作者及接受期刊/会议**：高德机器学习团队，KDD2020  
  **摘要**：时空预测在天气预报、运输规划等领域有着重要的应用价值。交通预测作为一种典型的时空预测问题，具有较高的挑战性。以往的研究中主要利用通行时间这类交通状态特征作为模型输入，很难预测整体的交通状况，本文提出的混合时空图卷积网络，利用导航数据大大提升了时空预测的效果。  
2. **题目**：[Recent Advances in Vision-and-Language Research](https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/)  
  **作者及接受期刊/会议**：微软和facebook的Licheng Yu, Yen-Chun Chen, Linjie Li，CVPR2020 workshop  
  **摘要**：视觉和语言(V+L)研究是计算机视觉和自然语言处理之间联系的一个有趣的领域，并迅速吸引了这两个领域的关注。各种各样的V+L任务，以大规模的人类注释数据集为基准，已经推动了联合多模态表示学习的巨大进步。本教程将重点介绍该领域中最近流行的一些任务，如视觉描述、视觉基准、视觉问题回答和推理、文本到图像的生成以及通用图像-文本表示的自监督学习。我们将涵盖这些领域的最新方法，并讨论集中体现多模态理解、推理和生成的核心挑战和机遇的关键原则。
3. **题目**：[Survey on Deep Multi-modal Data Analytics: Collaboration, Rivalry and Fusion](https://arxiv.org/abs/2006.08159)  
  **作者及接受期刊/会议**：合肥工业大学  
  **摘要**：随着web技术的发展，多模态或多视图数据已经成为大数据的主要流，每个模态/视图编码数据对象的单个属性。不同的模态往往是相辅相成的。这就引起了人们对融合多模态特征空间来综合表征数据对象的研究。大多数现有的先进技术集中于如何融合来自多模态空间的能量或信息，以提供比单一模态的同行更优越的性能。最近，深度神经网络展示了一种强大的架构，可以很好地捕捉高维多媒体数据的非线性分布，对多模态数据自然也是如此。大量的实证研究证明了深多模态方法的优势，从本质上深化了多模态深特征空间的融合。在这篇文章中，我们提供了从浅到深空间的多模态数据分析领域的现有状态的实质性概述。在整个调查过程中，我们进一步指出，该领域的关键要素是多模式空间的协作、对抗性竞争和融合。最后，我们就这一领域未来的一些方向分享我们的观点。  
4. **题目**：[Learning Representations via Graph-structured Networks](https://xiaolonw.github.io/graphnnv2/)  
  **作者及接受期刊/会议**：CVPR 2020, The 2nd Tutorial  
  **摘要**：近年来，卷积神经网络(ConvNets)在大量计算机视觉任务中的应用出现了戏剧性的增长。卷积结构在许多任务中都是非常强大的，它可以从图像像素中提取相关性和抽象概念。然而，当面对一些更困难的计算机视觉任务时，ConvNets在建模中也有相当多的属性方面存在缺陷。这些属性包括成对关系、全局上下文和处理超越空间网格的不规则数据的能力。一个有效的方向是根据手头的任务重新组织要用图处理的数据，同时构建网络模块，在图内的视觉元素之间关联和传播信息。我们将这种具有传播模块的网络称为图网络结构。在本教程中，我们将介绍一系列有效的图网络结构，包括非局部神经网络、空间广义传播网络、面向对象和多主体行为建模的关系网络、面向3D领域的视频和数据的图网络。我们还将讨论如何利用图神经网络结构来研究连接模式。最后，我们将讨论在许多视觉问题中仍然存在的相关开放挑战。 
5. **题目**：[XGNN-可解释图神经网络，从模型级解释构建可信赖GNN](https://xiaolonw.github.io/graphnnv2/)  
  **作者及接受期刊/会议**：KDD2020  
  **摘要**：图神经网络通过聚合和结合邻居信息来学习节点特征，在许多图的任务中取得了良好的性能。然而，GNN大多被视为黑盒，缺乏人类可理解的解释。因此，如果不能解释GNN模型，就不能完全信任它们并在某些应用程序域中使用它们。在这项工作中，我们提出了一种新的方法，称为XGNN，在模型级别上解释GNN。我们的方法可以为GNNs的工作方式提供高层次的见解和一般性的理解。特别地，我们提出通过训练一个图生成器来解释GNN，使生成的图模式最大化模型的某种预测。我们将图形生成表述为一个强化学习任务，其中对于每一步，图形生成器预测如何向当前图形中添加一条边。基于训练后的GNN信息，采用策略梯度方法对图生成器进行训练。此外，我们还加入了一些图规则，以促使生成的图是有效的。在合成和真实数据集上的实验结果表明，我们提出的方法有助于理解和验证训练过的GNN。此外，我们的实验结果表明，所生成的图可以为如何改进训练的神经网络提供指导。
6. **题目**：[CLEVRER数据集，推动视频理解的因果逻辑推理](https://arxiv.org/abs/1910.01442) [Project](http://clevrer.csail.mit.edu/)  
  **作者及接受期刊/会议**：ICLR 2020 论文，麻省理工、DeepMind  
  **摘要**：提出了一种针对时间和因果推理问题的数据集，包含 20,000 个关于碰撞物体的合成视频以及 300,000 多个问题和答案，从互补的角度研究了视频中的时间和因果推理问题。
7. **题目**：[对视觉与语言的思考：从自洽、交互到共生](https://github.com/JDAI-CV/image-captioning)  
  **作者及接受期刊/会议**：CVPR 2020，京东AI研究院  
  **摘要**：纵观视觉与语言在这六年间的飞速发展史，它就仿佛是两种不同文化（计算机视觉与自然语言处理）的碰撞与交融。这里每一种文化最初的进化都是自洽的，即独立地演化形成一套完备的视觉理解或语言建模体系；演化至今，我们当前所迎来的则是两种文化间的交互，自此视觉理解和语言建模不再是简单串联的两个模块，而是通过互相的信息传递成为共同促进的一个整体；对于视觉与语言的未来，则一定是聚焦于两者更为本质和紧密的共生，它所渴望的，将是挣脱开数据标注的桎梏，在海量的弱监督甚至于无监督数据上找寻两者间最为本质的联系，并以之为起源，如「道生一，一生二，二生三，三生万物」一般，赋予模型在各种视觉与语言任务上的生命力。
