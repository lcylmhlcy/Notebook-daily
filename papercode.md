## multimodal
- [OpenVQA](https://github.com/MILVLG/openvqa)
- [CVPR2019] [MUREL: Multimodal Relational Reasoning for Visual Question Answering](https://github.com/Cadene/murel.bootstrap.pytorch)
- [CVPR2019] [Composing Text and Image for Image Retrieval](https://github.com/google/tirg)
- [ICCV2019] [Zero-Shot Grounding of Objects from Natural Language Queries](https://github.com/TheShadow29/zsgnet-pytorch)
- [CVPRW2020] [Recent Advances in Vision-and-Language Research](https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/), Microstft & Fackbook
- [Survey on Deep Multi-modal Data Analytics: Collaboration, Rivalry and Fusion](https://arxiv.org/abs/2006.08159)
- [CVPR2020] [对视觉与语言的思考：从自洽、交互到共生](https://github.com/JDAI-CV/image-captioning)
- [CVPR2020] [Say As Y ou Wish: Fine-grained Control of Image Caption Generation with Abstract Scene Graphs](https://arxiv.org/pdf/2003.00387.pdf)
- [CVPR2020] [Spatio-Temporal Graph for Video Captioning with Knowledge Distillation](https://arxiv.org/pdf/2003.13942.pdf)
- [CVPR2020] [Object Relational Graph with Teacher-Recommended Learning for Video Captioning](https://arxiv.org/pdf/2002.11566.pdf)
- [CVPR2020] [Counterfactual Samples Synthesizing for Robust VQA](https://github.com/yanxinzju/CSS-VQA)
- [CVPR2020] [Hierarchical Conditional Relation Networks for Video Question Answering](https://github.com/thaolmk54/hcrn-videoqa)
- [ICLR2020] [VL-BERT: Pre-training of Generic Visual-Linguistic Representations](https://arxiv.org/abs/1908.08530), 微软亚洲研究院
- [ACMMM2020] [KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue](https://www.zhuanzhi.ai/paper/6a3e359d8827752a98f2e5daa7079d2a)
- [NIPS2020] [Deep Multimodal Fusion by Channel Exchanging](https://github.com/yikaiw/CEN)
- [CVPR2021] [VirTex: Learning Visual Representations from Textual Annotations](https://github.com/kdexd/virtex)
- [AAAI2021] [SMIL: Multimodal Learning with Severely Missing Modality](https://arxiv.org/pdf/2103.05677.pdf) [[Code]](https://github.com/mengmenm/SMIL)
- [ICLR2021] [Iterated learning for emergent systematicity in VQA](https://openreview.net/pdf?id=Pd_oMxH8IlF)


## Video/Action
- [ACMMM2020] [Dual Temporal Memory Network for Efficient Video Object Segmentation](https://arxiv.org/abs/2003.06125)
- [ICCV2019] [Compositional Video Prediction](https://github.com/JudyYe/CVP)
- [Reformulating HOI Detection as Adaptive Set Prediction](https://arxiv.org/pdf/2103.05983.pdf)
- [ICLR2021] [AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition](https://arxiv.org/pdf/2102.05775.pdf) [[Code]](https://github.com/mengyuest/AdaFuse)


## Graph NN
- [CVPR2020 Tutorial][Learning Representations via Graph-structured Networks](https://xiaolonw.github.io/graphnnv2/)
- [KDD2020] [XGNN-可解释图神经网络，从模型级解释构建可信赖GNN](https://xiaolonw.github.io/graphnnv2/)
- [ICML2020] [Contrastive Multi-View Representation Learning on Graphs](https://arxiv.org/pdf/2006.05582.pdf)
- [NIPS2020] [Graph Mining and Learning](https://gm-neurips-2020.github.io/)
- [Contrastive Learning of Structured World Models](https://github.com/tkipf/c-swm)


## 1D data
- [KDD2020] [Hybrid Spatio-Temporal Graph Convolutional Network: Improving Traffic Prediction with Navigation Data](https://arxiv.org/abs/2006.12715), 高德机器学习团队 


## Reasoning
- [ICLR2020] [CLEVRER数据集，推动视频理解的因果逻辑推理](https://arxiv.org/abs/1910.01442), MIT & DeepMind, [[Project]]
- [CVPR2020] [Graph-Structured Referring Expression Reasoning in The Wild](https://arxiv.org/pdf/2004.08814.pdf) [[Github]](https://github.com/sibeiyang/sgmn)
- [ICCV2017] [Inferring and Executing Programs for Visual Reasoning](https://github.com/facebookresearch/clevr-iep)
- [CVPR2021] [Transformation driven Visual Reasoning](https://github.com/hughplay/TVR)


## Causal
- [CVPR2020] [Visual Commonsense R-CNN](https://arxiv.org/abs/2002.12204), 电子科技大学&阿里达摩院  [[zhihu]](https://zhuanlan.zhihu.com/p/111306353) [[Github]](https://github.com/Wangt-CN/VC-R-CNN)
- [《数据因果性学习: 问题与方法》2020综述论文](https://www.zhuanzhi.ai/paper/6ad7902913e98bd48540a5596b978edc)
- [Extracting Causal Viusal Features for Limited Lable Classification](https://arxiv.org/pdf/2103.12322.pdf)


## Bayes
- [贝叶斯深度学习2020综述论文](https://www.zhuanzhi.ai/paper/9b781282204cb581a31aa0e8b570dd95), MIT&港科大  
- [Bayesian neural network using Pyro and PyTorch on MNIST dataset](https://github.com/paraschopra/bayesian-neural-network-mnist)


## Dataset and preprocess
- [CVPR2011] [Unbiased look at dataset bias](https://ieeexplore.ieee.org/abstract/document/5995347), MIT.
- [ACPR2017] [A Deeper Look at Dataset Bias](https://link.springer.com/chapter/10.1007/978-3-319-58347-1_2)
- [Arxiv2018] [Why do deep convolutional networks generalize so poorly to small image transformations?](https://www.jmlr.org/papers/volume20/19-519/19-519.pdf)
- [ICML2019] [Making Convolutional Networks Shift-Invariant Again](https://github.com/adobe/antialiased-cnns)
- [CVPR2020] [Destruction and Construction Learning for Fine-grained Image Recognition](https://github.com/JDAI-CV/DCL)
- [CVPR2021] [MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition](https://github.com/BIT-DA/MetaSAug)
- [CVPR2021] [Learning Continuous Image Representation with Local Implicit Image Function](https://github.com/yinboc/liif)
- [CVPR2021] [CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning]()
- [CVPR2021] [Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification](https://arxiv.org/pdf/2103.14267.pdf) [[Code]](https://k-han.github.io/HybridLT)


## Few-shot/meta
- [ECCv2018] [Partial Convolution Layer for Padding and Image Inpainting](https://github.com/NVIDIA/partialconv)
- [CVPR2018] [Learning to Compare: Relation Network for Few-Shot Learning](https://github.com/floodsung/LearningToCompare_FSL)
- [Code for few shot](https://github.com/oscarknagg/few-shot)
- [Hands-On-Meta-Learning-With-Python](https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python)
- [NIPS2019] [Visual Concept-Metaconcept Learning (VCML)](https://github.com/Glaciohound/VCML)
- [CVPR2021] [Towards Open World Object Detection](https://github.com/JosephKJ/OWOD)
- [CVPR2021] [Counterfactual Zero-Shot and Open-Set Visual Recognition](https://arxiv.org/abs/2103.00887)
- [ICLR2021] [Concept Learners for Few-Shot Learning](https://github.com/snap-stanford/comet)

## Semi-supervised/Unsupervised
- [CVPR2021] [SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification](https://arxiv.org/pdf/2103.16725.pdf) [[Code]](https://github.com/zijian-hu/SimPLE)
- [LeCun] [Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230)


## Interpret
- [CVPR2019] [Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks](https://arxiv.org/abs/1908.02686)


## Others
- [ICLR2021] [he Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers](https://arxiv.org/pdf/2010.08127.pdf) [[Dataset]](https://github.com/preetum/cifar5m)
- [CVPR2021] [Dynamic Metric Learning: Towards a Scalable Metric Space to Accommodate Multiple Semantic Scales](https://arxiv.org/pdf/2103.11781v1.pdf) [[Code]](https://github.com/SupetZYK/DynamicMetricLearning)
- [亚利桑那州立大学周纵苇：视觉的目的是什么？](https://hub.baai.ac.cn/view/6777)
- [Li Feifei] [Embodied Intelligence via Learning and Evolution](https://arxiv.org/pdf/2102.02202.pdf)