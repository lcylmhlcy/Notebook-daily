## Few-shot/meta/openset
- [Demo] [Code for few shot](https://github.com/oscarknagg/few-shot)
- [Demo] [Hands-On-Meta-Learning-With-Python](https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python)

### graph
- [NIPS2019] [Learning to Propagate for **Graph** Meta-Learning](https://arxiv.org/abs/1909.05024) [[Code](https://github.com/liulu112601/Gated-Propagation-Net)]

### others based
- [NIPS1996] [Is learning the n-th thing any easier than learning the first?](https://people.eecs.berkeley.edu/~russell/classes/cs294/f05/papers/thrun-1996.pdf)
- [TPAMI2006] [One-shot learning of object categories](https://ieeexplore.ieee.org/abstract/document/1597116) [**Feifei Li**]
- [2014] [Tinkering Under the Hood: Interactive Zero-Shot Learning with Net Surgery](https://arxiv.org/abs/1612.04901)
- [ICCV2015] [One Shot Learning via Compositions of Meaningful Patches](https://ieeexplore.ieee.org/abstract/document/7410499)
- [ECCV2016] [Learning to learn: Model regression networks for easy small sample learning](https://link.springer.com/chapter/10.1007/978-3-319-46466-4_37)
- [ICLR2017] [Optimization as a Model for Few-Shot Learning](https://openreview.net/forum?id=rJY0-Kcll)
- [ICML2017] [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400)
- [NIPS2018] [TADAM: Task dependent adaptive metric for improved few-shot learning](https://arxiv.org/abs/1805.10123) [[Code](https://github.com/ElementAI/TADAM)]
- [ICLR2021] [Zero-shot Synthesis with Group-Supervised Learning](https://arxiv.org/abs/2009.06586) [[Code](https://github.com/gyhandy/Group-Supervised-Learning)]

### openset
- [CVPR2021] [Towards Open World Object Detection](https://arxiv.org/abs/2103.02603) [[Code](https://github.com/JosephKJ/OWOD)]
- [CVPR2021] [Counterfactual Zero-Shot and Open-Set Visual Recognition](https://arxiv.org/abs/2103.00887) [[Code](https://github.com/yue-zhongqi/gcm-cf)]



## Interpret
- [NIPS2009] [Reading tea leaves: How humans interpret topic models](https://www.cs.ubc.ca/~rjoty/Webpage/nips2009-rtl.pdf)
- [ICLRW2014] [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/abs/1312.6034)
- [2014] [Methods and Models for Interpretable Linear Classification](https://arxiv.org/abs/1405.4047)
- [ECCV2014] [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)
- [NIPS2014] [The bayesian case model: A generative approach for case-based reasoning and prototype classification](https://proceedings.neurips.cc/paper/2014/file/390e982518a50e280d8e2b535462ec1f-Paper.pdf)
- [CVPR2015] [Understanding Deep Image Representations by Inverting Them](https://arxiv.org/abs/1412.0035)
- [AISTATS2015] [Falling Rule Lists](https://arxiv.org/abs/1411.5899)
- [2016] [Model-Agnostic Interpretability of Machine Learning](https://arxiv.org/abs/1606.05386)
- [KDD2016] ["Why Should I Trust You?": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)
- [NIPS2016] [Examples are not enough, learn to criticize! Criticism for Interpretability](http://edithlaw.ca/teaching/cs889/2018/reading/Experimenting/Paper8.pdf)
- [TNNLS2016] [Evaluating the visualization of what a Deep Neural Network has learned](https://arxiv.org/abs/1509.06321)
- [2017] [SmoothGrad: removing noise by adding noise](https://arxiv.org/abs/1706.03825)
- [NIPS2017] [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)
- [NIPS2017] [Real Time Image Saliency for Black Box Classifiers](https://arxiv.org/abs/1705.07857)
- [ICML2017] [Axiomatic Attribution for Deep Networks](https://arxiv.org/abs/1703.01365)
- [ICML2017] [Understanding Black-box Predictions via Influence Functions](https://arxiv.org/abs/1703.04730)
- [ICCV2017] [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02391)
- [ICCV2017] [Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/abs/1704.03296) [[SUP](https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fong_Interpretable_Explanations_of_ICCV_2017_supplemental.pdf)]
- [CVPR2017] [Network Dissection: Quantifying Interpretability of Deep Visual Representations](https://arxiv.org/abs/1704.05796)
- [NIPS2018] [Towards Robust Interpretability with Self-Explaining Neural Networks](https://arxiv.org/abs/1806.07538)
- [NIPS2018] [Sanity checks for saliency maps](https://arxiv.org/abs/1810.03292) [**Goodfellow**]
- [AAAI2018] [Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions](https://arxiv.org/abs/1710.04806)
- [CVPR2018] [Deep Image Prior](https://arxiv.org/abs/1711.10925) [[Code](https://github.com/DmitryUlyanov/deep-image-prior)]
- [CVPR2018] [The unreasonable effectiveness of deep features as a perceptual metric](https://arxiv.org/abs/1801.03924) [[Code](https://github.com/richzhang/PerceptualSimilarity)]
- [TPAMI2018] [Interpreting Deep Visual Representations via Network Dissection](https://ieeexplore.ieee.org/abstract/document/8417924)
- [DSAA2018] [Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/abs/1806.00069)
- [CSUR2018] [A Survey Of Methods For Explaining Black Box Models](https://arxiv.org/abs/1802.01933)
- [ICLR2018] [Towards better understanding of gradient-based attribution methods for Deep Neural Networks](https://openreview.net/pdf?id=Sy21R9JAW)
- [CVPR2019] [Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks](https://arxiv.org/abs/1908.02686)
- [CVPR2019] [Interpreting CNNs via Decision Trees](https://arxiv.org/abs/1802.00121)
- [CVPR2019] [Learning to Explain With Complemental Examples](https://arxiv.org/abs/1812.01280)
- [NIPS2019] [This Looks Like That: Deep Learning for Interpretable Image Recognition](https://arxiv.org/abs/1806.10574)
- [NIPS2019] [On the (In)fidelity and Sensitivity for Explanations](https://arxiv.org/abs/1901.09392)
- [AAAI2019] [Interpretation of Neural Networks is Fragile](https://arxiv.org/abs/1710.10547)
- [AISTATS2019] [Knockoffs for the mass: new feature importance statistics with false discovery guarantees](https://arxiv.org/abs/1807.06214)
- [ExplainableAI2019] [The (un) reliability of saliency methods](https://arxiv.org/abs/1711.00867) [**Been Kim**]
- [NIPS2019] [A Benchmark for Interpretability Methods in Deep Neural Networks](https://arxiv.org/abs/1806.10758)
- [2019] [Interpretability beyond classification output: Semantic bottleneck networks](https://arxiv.org/abs/1907.10882)
- [2019] [Evaluating Explanation Without Ground Truth in Interpretable Machine Learning](https://arxiv.org/abs/1907.06831)
- [NIPS2020] [Debugging Tests for Model Explanations](https://arxiv.org/abs/2011.05429) [**Been Kim**]
- [CHI2021] [Manipulating and Measuring Model Interpretability](https://arxiv.org/abs/1802.07810)
- [Computational Brain & Behavior (2021)] [Neural Networks Trained on Natural Scenes Exhibit Gestalt Closure](https://arxiv.org/abs/1903.01069) [**Been Kim**]



## Semi-supervised/Unsupervised
- [ICCV2015] [Unsupervised Visual Representation Learning by Context Prediction](https://arxiv.org/abs/1505.05192)
- [CVPR2018] [Unsupervised discovery of object landmarks as structural representations](https://arxiv.org/abs/1804.04412) [[Code](https://github.com/YutingZhang/lmdis-rep)]
- [ICML2019] [Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations](https://arxiv.org/abs/1811.12359)
- [CVPR2021] [SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification](https://arxiv.org/pdf/2103.16725.pdf) [[Code](https://github.com/zijian-hu/SimPLE)]
- [CVPR2021] [CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning](https://arxiv.org/abs/2102.09559)
- [CVPR2021] [Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification](https://arxiv.org/pdf/2103.14267.pdf) [[Code](https://k-han.github.io/HybridLT)]



## Dataset and preprocess
- [CVPR2011] [Unbiased look at dataset bias](https://ieeexplore.ieee.org/abstract/document/5995347)
- [ACPR2017] [A Deeper Look at Dataset Bias](https://link.springer.com/chapter/10.1007/978-3-319-58347-1_2)
- [Arxiv2018] [Why do deep convolutional networks generalize so poorly to small image transformations?](https://www.jmlr.org/papers/volume20/19-519/19-519.pdf)
- [ICML2019] [Making Convolutional Networks Shift-Invariant Again](https://arxiv.org/abs/1904.11486) [[Code](https://github.com/adobe/antialiased-cnns)]
- [CVPR2019] [Destruction and Construction Learning for Fine-grained Image Recognition](https://openreview.net/forum?id=HibvKgQe_pH) [[Code](https://github.com/JDAI-CV/DCL)]
- [CVPR2021] [MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition](https://arxiv.org/abs/2103.12579) [[Code](https://github.com/BIT-DA/MetaSAug)]
- [CVPR2021] [Learning Continuous Image Representation with Local Implicit Image Function](https://arxiv.org/abs/2012.09161) [[Code](https://github.com/yinboc/liif)]
- [CVPR2021] [Noise-resistant Deep Metric Learning with Ranking-based Instance Selection](https://arxiv.org/abs/2103.16047) [[Code](https://github.com/alibaba-edu/Ranking-based-Instance-Selection)]
  - 第一篇尝试解决存在大量标签噪音的深度度量学习问题
- [CVPR2021] [Correlated Input-Dependent Label Noise in Large-Scale Image Classification](https://arxiv.org/abs/2105.10305) [**GoogleAI**]
- [CVPR2021] [Deep Stable Learning for Out-Of-Distribution Generalization](https://arxiv.org/abs/2104.07876)
- [ICML2021] [Delving into Deep Imbalanced Regression](https://arxiv.org/abs/2102.09554) [[Code](https://github.com/YyzHarry/imbalanced-regression)]



## MLP
- [ICLR2021] [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
- [2021] [MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/pdf/2105.01601.pdf) [[Code](https://github.com/google-research/vision_transformer/tree/linen)]



## Reasoning
- [ICLR2020] [CLEVRER: CoLlision Events for Video REpresentation and Reasoning](https://arxiv.org/abs/1910.01442) [**DeepMind**] [[Project](http://clevrer.csail.mit.edu/)]
- [CVPR2020] [Graph-Structured Referring Expression Reasoning in The Wild](https://arxiv.org/pdf/2004.08814.pdf) [[Github](https://github.com/sibeiyang/sgmn)]
- [ICCV2017] [Inferring and Executing Programs for Visual Reasoning](https://arxiv.org/abs/1705.03633) [[Code](https://github.com/facebookresearch/clevr-iep)]
- [CVPR2021] [Transformation driven Visual Reasoning](https://arxiv.org/pdf/2011.13160) [[Code](https://github.com/hughplay/TVR)]
- [ICML2021] [Efficient Iterative Amortized Inference for Learning Symmetric and Disentangled Multi-Object Representations](http://arxiv.org/abs/2106.03630v1) [[Code](https://github.com/pemami4911/EfficientMORL)]



## Causal
- [CVPR2020] [Visual Commonsense R-CNN](https://arxiv.org/abs/2002.12204) [[zhihu](https://zhuanlan.zhihu.com/p/111306353)] [[Github](https://github.com/Wangt-CN/VC-R-CNN)]
- [2021] [A Survey of Learning Causality with Data: Problems and Methods](https://arxiv.org/abs/1809.09337v4)
- [2021] [Extracting Causal Viusal Features for Limited Lable Classification](https://arxiv.org/pdf/2103.12322.pdf)



## Bayes
- [2021] [A Survey on Bayesian Deep Learning](https://arxiv.org/abs/1604.01662v4) 
- [Demo] [Bayesian neural network using Pyro and PyTorch on MNIST dataset](https://github.com/paraschopra/bayesian-neural-network-mnist)



## multimodal
- [Dataset] [OpenVQA](https://github.com/MILVLG/openvqa)
- [CVPR2019] [MUREL: Multimodal Relational Reasoning for Visual Question Answering](https://arxiv.org/abs/1902.09487) [[Code](https://github.com/Cadene/murel.bootstrap.pytorch)]
- [CVPR2019] [Composing Text and Image for Image Retrieval](https://arxiv.org/abs/1812.07119) [[Code](https://github.com/google/tirg)]
- [ICCV2019] [Zero-Shot Grounding of Objects from Natural Language Queries](https://arxiv.org/abs/1908.07129) [[Code](https://github.com/TheShadow29/zsgnet-pytorch)]
- [CVPR2020 Tutorial] [Recent Advances in Vision-and-Language Research](https://rohit497.github.io/Recent-Advances-in-Vision-and-Language-Research/)
- [Survey on Deep Multi-modal Data Analytics: Collaboration, Rivalry and Fusion](https://arxiv.org/abs/2006.08159)
- [CVPR2020] [X-Linear Attention Networks for Image Captioning](https://arxiv.org/pdf/2003.14080.pdf) [[Code](https://github.com/JDAI-CV/image-captioning)]
- [CVPR2020] [Say As You Wish: Fine-grained Control of Image Caption Generation with Abstract Scene Graphs](https://arxiv.org/pdf/2003.00387.pdf)
- [CVPR2020] [Spatio-Temporal Graph for Video Captioning with Knowledge Distillation](https://arxiv.org/pdf/2003.13942.pdf)
- [CVPR2020] [Object Relational Graph with Teacher-Recommended Learning for Video Captioning](https://arxiv.org/pdf/2002.11566.pdf)
- [CVPR2020] [Counterfactual Samples Synthesizing for Robust VQA](https://arxiv.org/pdf/2003.06576.pdf) [[Code](https://github.com/yanxinzju/CSS-VQA)]
- [CVPR2020] [Hierarchical Conditional Relation Networks for Video Question Answering](https://arxiv.org/abs/2002.10698) [[Code](https://github.com/thaolmk54/hcrn-videoqa)]
- [ICLR2020] [VL-BERT: Pre-training of Generic Visual-Linguistic Representations](https://arxiv.org/abs/1908.08530)
- [ACMMM2020] [KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue](https://arxiv.org/abs/2008.04858v2)
- [NIPS2020] [Deep Multimodal Fusion by Channel Exchanging](https://papers.nips.cc/paper/2020/file/339a18def9898dd60a634b2ad8fbbd58-Paper.pdf) [[Code](https://github.com/yikaiw/CEN)]
- [CVPR2021] [VirTex: Learning Visual Representations from Textual Annotations](https://arxiv.org/abs/2006.06666) [[Code](https://github.com/kdexd/virtex)]
- [AAAI2021] [SMIL: Multimodal Learning with Severely Missing Modality](https://arxiv.org/pdf/2103.05677.pdf) [[Code](https://github.com/mengmenm/SMIL)]
- [ICLR2021] [Iterated learning for emergent systematicity in VQA](https://openreview.net/pdf?id=Pd_oMxH8IlF)
- [ICLR2021] [Trusted Multi-View Classification](https://arxiv.org/abs/2102.02051) [[Code](https://github.com/hanmenghan/TMC)]



## Video/Action
- [ACMMM2020] [Dual Temporal Memory Network for Efficient Video Object Segmentation](https://arxiv.org/abs/2003.06125)
- [ICCV2019] [Compositional Video Prediction](https://arxiv.org/abs/1908.08522) [[Code](https://github.com/JudyYe/CVP)]
- [2021] [Reformulating HOI Detection as Adaptive Set Prediction](https://arxiv.org/pdf/2103.05983.pdf)
- [ICLR2021] [AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition](https://arxiv.org/pdf/2102.05775.pdf) [[Code](https://github.com/mengyuest/AdaFuse)]
- [CVPR2021] [Self-supervised Video Representation Learning by Context and Motion Decoupling](https://arxiv.org/abs/2104.00862)



## Graph NN
- [CVPR2020 Tutorial] [Learning Representations via Graph-structured Networks](https://xiaolonw.github.io/graphnnv2/)
- [KDD2020] [Xgnn: Towards model-level explanations of graph neural networks](https://arxiv.org/abs/2006.02587)
- [ICML2020] [Contrastive Multi-View Representation Learning on Graphs](https://arxiv.org/pdf/2006.05582.pdf)
- [NIPS2020 Tutorial] [Graph Mining and Learning](https://gm-neurips-2020.github.io/)
- [2020] [Contrastive Learning of Structured World Models](http://arxiv.org/abs/1911.12247) [[Code](https://github.com/tkipf/c-swm)]
- [ICLRW2020] [An Energy-Based View of Graph Neural Networks](https://arxiv.org/abs/2104.1349)
- [ICML2021] [Graphnorm: A principled approach to accelerating graph neural network training](https://arxiv.org/abs/2009.03294) [[Code](https://github.com/lsj2408/GraphNorm)]



## 1D data
- [KDD2020] [Hybrid Spatio-Temporal Graph Convolutional Network: Improving Traffic Prediction with Navigation Data](https://arxiv.org/abs/2006.12715)



## Others
- [ECCV2018] [Partial Convolution Layer for Padding and Image Inpainting](https://arxiv.org/pdf/1811.11718.pdf) [[Code](https://github.com/NVIDIA/partialconv)]
- [ICLR2021] [The Deep Bootstrap Framework: Good Online Learners are Good Offline Generalizers](https://arxiv.org/pdf/2010.08127.pdf) [[Dataset](https://github.com/preetum/cifar5m)]
- [CVPR2021] [Dynamic Metric Learning: Towards a Scalable Metric Space to Accommodate Multiple Semantic Scales](https://arxiv.org/pdf/2103.11781v1.pdf) [[Code](https://github.com/SupetZYK/DynamicMetricLearning)]
- [亚利桑那州立大学周纵苇：视觉的目的是什么？](https://hub.baai.ac.cn/view/6777)
- [2021] [Embodied Intelligence via Learning and Evolution](https://arxiv.org/pdf/2102.02202.pdf) [**Feifei Li**]
- [ICML2021] [Cross-domain Imitation from Observations](https://arxiv.org/abs/2105.10037)